# ğŸš€ Gen AI Integrated Platform support Environment(IPE)

## ğŸ“Œ Table of Contents
- [Introduction](#introduction)
- [Demo](#demo)
- [Inspiration](#inspiration)
- [What It Does](#what-it-does)
- [How We Built It](#how-we-built-it)
- [Challenges We Faced](#challenges-we-faced)
- [How to Run](#how-to-run)
- [Tech Stack](#tech-stack)
- [Team](#team)

---

## ğŸ¯ Introduction
Challenge Overview:
Currently Technology orgnization has a large platfrom support system which provides L1/2/3 support. Platform support requires trouble shooting, accessing variety of Knowledge base articles,running ansible automation scripts, foundational information about configuration items including thier relationships, dependencies, health, etc, etc. 

Problem statement:
All these tools require frequent context switching causing significant overhead in accesing different tools. Develop a Gen-AI enabled Integrated Platform Environment(IPE) that provides an integrated console to platform support teams with following capabilities:
1. Provide agentic capabilities for incident resolution
2. AI chatbot to contextually chat with a GPT backend on the incident/issue that they are resolving at the moment
3. Contextual recommendations
4. Ability to leverage enterprise information for troubleshooting
5. Context based data extraction

   Integrated Platform Environment should be the one-stop environment for all platform support users/teams for identifying, resolving and responding to all incidents.

## ğŸ¥ Demo
ğŸ”— [Live Demo](#) (if applicable)  
ğŸ“¹ [Video Demo](#) (if applicable)  
ğŸ–¼ï¸ Screenshots:

![Screenshot 1](link-to-image)

## ğŸ’¡ Inspiration
I am part of Enteprise platforms and partner success team and connected with platform support use case. This use case has potential to change the support work and easy detection of resolutions.

## âš™ï¸ What It Does
Explain the key features and functionalities of your project.
- Ui view of Integrated Platform Environemnt(IPE)
- Utilize LLM's to provide the required capabilities like incident resolution, RCA, dependencies, health, etc.
- End-to-end journey of an incident and how levergaing GenAI will simplify these capabilities
- Scalable, explainable, efficient and seamless integration into existing applications


## ğŸ› ï¸ How We Built It
Briefly outline the technologies, frameworks, and tools used in development.
1)Langflow under Langchain framework is used, which is a new, visual framework for building multi-agent and RAG applications. It is open-source, Python-powered, fully customizable, and LLM and vector store agnostic. Its intuitive interface allows for easy manipulation of AI building blocks, enabling developers to quickly prototype and turn their ideas into powerful, real-world solutions.Langflow empowers developers to rapidly prototype and build AI applications with its user-friendly interface and powerful features. 
2) AI chatbot using Input chatbot and output chatbot components
3) RAG Agents are used for implementing fucntionalities
4) Used OpenAI API keys to use LLM model "gpt-40-mini"
5) Used ASTRA DB and API keys to store vector embeddings into AstraDB
6) Prompt component used for for structuring prompts and passing dynamic data to a language model.
7) Textsplitter component to split input data into chunks
8) Duckduckgo search component to get the information when no information is availble in input data.
9) python code to run langflow in local 




## ğŸš§ Challenges We Faced
Describe the major technical or non-technical challenges your team encountered.
- lack of correct Input data sets 
- Merging data sets as each data set is not linked to other data sets
- Time constraints
- I tried with Langchain intitially but loading data into vector DB is not working(Lot of debugging needs to be done which took all the time)
- Configuration on my personal system did not allow me to run the langflow code as pip install langflow ran for 6 hours and i have stopped as system is going out of memory
- Clarity in requirements ex: console UI view



## ğŸƒ How to Run
1. Clone the repository  
   ```sh
   git clone https://github.com/your-repo.git
   ```
2. Install dependencies  
   ```sh
   npm install  # or pip install -r requirements.txt (for Python)
   ```
3. Run the project  
   ```sh
   npm start  # or python app.py
   ```

## ğŸ—ï¸ Tech Stack
- ğŸ”¹ Frontend: React / Vue / Angular / Datstax langflow
- ğŸ”¹ Backend: python/ gpt-40-mini
- ğŸ”¹ Database: ASTRA DB
- ğŸ”¹ Other: OpenAI API / ASRTA DB API / Langflow agents

## ğŸ‘¥ Team
- Swapna Mamilla - [github.com/SwapnaMamilla)](https://github.com/SwapnaMamilla) | [LinkedIn](#)
- Ramys Naga - [GitHub](#) | [LinkedIn](#)
